```
______                                                                     
| ___ \                                                                    
| |_/ / __ ___   ___ ___  ___ ___                                          
|  __/ '__/ _ \ / __/ _ \/ __/ __|                                         
| |  | | | (_) | (_|  __/\__ \__ \                                         
\_|  |_|  \___/ \___\___||___/___/                                         
                                                                        
 _____                  _                     _          _   _             
/  ___|                | |                   (_)        | | (_)            
\ `--. _   _ _ __   ___| |__  _ __ ___  _ __  _ ______ _| |_ _  ___  _ __  
 `--. \ | | | '_ \ / __| '_ \| '__/ _ \| '_ \| |_  / _` | __| |/ _ \| '_ \ 
/\__/ / |_| | | | | (__| | | | | | (_) | | | | |/ / (_| | |_| | (_) | | | |
\____/ \__, |_| |_|\___|_| |_|_|  \___/|_| |_|_/___\__,_|\__|_|\___/|_| |_|
        __/ |                                                              
       |___/                                                               
```

#### A cooperating process is one that can affect or be affected by other processes executing in the system. Cooperating processes can either directly share a logical address space (that is, both code and data) or be allowed to share data only through files or messages.

Let’s consider an example to highlight the need for process synchronization.


A producer process produces information that is consumed by a consumer process. For example, a compiler may produce assembly code that is consumed by an assembler. The assembler, in turn, may produce object modules that are consumed by the loader. The producer–consumer problem also provides a useful metaphor for the client–server paradigm.

One solution to the producer–consumer problem uses shared memory. To allow producer and consumer processes to run concurrently, we must have available a buffer of items that can be filled by the producer and emptied by the consumer. Two types of buffers can be used. The ```unbounded buffer``` places no practical limit on the size of the buffer. The consumer may have to wait for new items, but the producer can always produce new items. The ```bounded buffer``` assumes a fixed buffer size. In this case, the consumer must wait if the buffer is empty, and the producer must wait if the buffer is full.

```c
/               *Producer code*/
while (true) {
        /* produce an item in next produced */
        while (counter == BUFFER SIZE)
                ; /* do nothing */
        
        buffer[in] = next produced;
        in = (in + 1) % BUFFER SIZE; //buffer is implementea as a circular array
        counter++;
}
```
```c
                /*Consumer code*/
while (true) {
        while (counter == 0)
                ; /* do nothing */
        next consumed = buffer[out];
        out = (out + 1) % BUFFER SIZE;
        counter--;
        /* consume the item in next consumed */
}
```

These two processes running concurrently can result in a race condition. Let's consider that we start with the counter on the value 5. The concurrent execution of “counter++” and “counter--” is equivalent to a sequential execution in which the lower-level statements are interleaved in some arbitrary order (but the order within each high-level statement is preserved). One such interleaving is the following:
```
T0 :    producer        execute         register1 = counter             {r egister1 = 5}
T1 :    producer        execute         register1 = register1 + 1       {r egister1 = 6}
T2 :    consumer        execute         register2 = counter             {r egister2 = 5}
T3 :    consumer        execute         r egister2 = r egister2 − 1     {r egister2 = 4}
T4 :    producer        execute         counter = r egister1            {counter = 6}
T5 :    consumer        execute         counter = r egister2            {counter = 4}
```
Notice that we have arrived at the incorrect state “counter == 4”, indicating that four buffers are full, when, in fact, five buffers are full. If we reversed the order of the statements at T4 and T5 , we would arrive at the incorrect state “counter == 6”. We would arrive at this incorrect state because we allowed both processes to manipulate the variable counter concurrently.

#### The Critical-Section Problem

We begin our consideration of process synchronization by discussing the so-called critical-section problem. Consider a system consisting of n processes {P0 , P1 , ..., Pn−1 }. Each process has a segment of code, called a critical section, in which the process may be changing common variables, updating a table, writing a file, and so on. The important feature of the system is that, when one process is executing in its critical section, no other process is allowed to execute in its critical section. That is, no two processes are executing in their critical sections at the same time. The critical-section problem is to design a protocol that the processes can use to cooperate. Each process must request permission to enter its critical section. The section of code implementing this request is the entry section. The critical section may be followed by an exit section. The remaining code is the remainder section. The general structure of a typical process Pi is shown below:
```c
do {
        +---------------+
        | entry section |
        +---------------+

                critical section

        +--------------+
        | exit section |
        +--------------+

                remainder section

} while (true);
```
A solution to the critical-section problem must satisfy the following three requirements:
1. ```Mutual exclusion.``` If process Pi is executing in its critical section, then no other processes can be executing in their critical sections.
2. ```Progress.``` If no process is executing in its critical section and some processes wish to enter their critical sections, then only those processes that are not executing in their remainder sections can participate in deciding which will enter its critical section next, and this selection cannot be postponed indefinitely.
3. ```Bounded waiting.``` There exists a bound, or limit, on the number of times
that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that
request is granted.


#### Kernel code (code implementing an operating system) is subject to several race conditions. 

Consider as an example a ```kernel data structure``` that mentain a ```list of all open files in system```. This list must be modified when a new file is opened or closed (adding the file to the list or removing it from the list). If two processes were to open files simultaneously, the separate updates to this list could result in a race condition.

Other ```kernel data structures``` that are prone to possible race conditions include ```structures for maintaining memory allocation```, for maintaining process lists, and for interrupt handling. It is up to kernel developers to ensure that the operating system is free from such race condition.

Two general approaches are used to handle critical sections in operating systems: ```preemptive kernels``` and ```nonpreemptive kernels```. A ```preemptive kernel``` allows a process to be preempted while it is running in kernel mode. A ```nonpreemptive kernel``` does not allow a process running in kernel mode to be preempted; a kernel-mode process will run until it exits kernel mode, blocks, or voluntarily yields control of the CPU.

### Peterson's Solution
Peterson’s solution is restricted to two processes that alternate execution between their critical sections and remainder sections. The processes are numbered P0 and P1 . For convenience, when presenting Pi , we use Pj to denote the other process; that is, ```j``` equals ```1 − i```.
```c
do {
        flag[i] = true;                 --+
        turn = j;                         | entry section
        while (flag[j] && turn == j);   --+
        
                critical section
        
        flag[i] = false;
        
        remainder section               | exit section
} while (true);
```

### Synchronization Hardware

Many modern computer systems therefore provide special hardware instructions that allow us either to test and modify the content of a word or to swap the contents of two words atomically—that is, as one uninterruptible unit. We can use these special instructions to solve the critical-section problem in a relatively simple manner. Rather than discussing one specific instruction for one specific machine, we abstract the main concepts behind these types of instructions by describing the test and set() and compare and swap() instructions.

#### The test and set() instruction can be defined below:
```c
bool test_and_set(bool *target) {
    bool rv = *target;
    *target = true;
    return rv;
}
```
```c
do {
    while (test_and_set(&lock))
        ; /* do nothing */

    /* critical section */
    
    lock = false;
    /* remainder section */
} while (true);
```

This code demonstrates a simple spinlock mechanism using the test_and_set function for mutual exclusion.

```test_and_set``` function: This function takes a pointer to a boolean variable (target) and performs an atomic operation. It saves the current value of *target in rv, sets *target to true (indicating the lock is acquired), and returns the original value. If *target was true, it means the lock was already held by another process.

```Main loop```:

The while (test_and_set(&lock)) loop continuously checks if the lock is available. If test_and_set returns true, the process waits; if it returns false, the lock is acquired.

```Critical Section```: After obtaining the lock, the code enters the critical section, where it performs operations that require exclusive access.

```Release Lock```: After the critical section, lock is set to false to release the lock, allowing other processes to enter the critical section.

This process repeats indefinitely due to the outer ```do...while(true)``` loop.
```c
/*An example of Test and set method in practice*/

#include <stdio.h>
#include <pthread.h>
#include <stdatomic.h>

// This flag will act as the lock indicator.
// "volatile" tells the compiler that this variable can be changed by other threads at any time,
// preventing optimizations that might interfere with correct operation.
volatile int lock_flag = 0; // lock_flag initialized to 0 (unlocked state)

// Lock function that implements the test-and-set behavior
void lock() {
    // __sync_lock_test_and_set() atomically sets lock_flag to 1 and returns the previous value of lock_flag.
    // If the previous value was 1, it means the lock is held by another thread, so this thread must wait.
    // The while loop repeatedly checks until the lock_flag is 0, allowing this thread to "acquire" the lock.
    while (__sync_lock_test_and_set(&lock_flag, 1)) {
        // Spin-wait (busy-waiting) until the lock becomes available.
    }
}

// Unlock function to release the lock
void unlock() {
    // __sync_lock_release() sets lock_flag back to 0 (unlocked),
    // allowing other threads to acquire the lock.
    __sync_lock_release(&lock_flag);
}

// Shared resource that needs protection by the lock
int shared_counter = 0;

// Function executed by each thread to increment the shared_counter
void* increment(void* arg) {
    // Each thread will try to increment the counter 100,000 times.
    for (int i = 0; i < 100000; ++i) {
        lock();               // Acquire the lock before entering critical section
        shared_counter++;     // Critical section: safely increment shared counter
        unlock();             // Release the lock after leaving critical section
    }
    return NULL;
}

int main() {
    pthread_t t1, t2; // Thread identifiers for two threads

    // Create two threads, each running the increment function
    pthread_create(&t1, NULL, increment, NULL);
    pthread_create(&t2, NULL, increment, NULL);

    // Wait for both threads to finish their execution
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);

    // Print the final value of the shared_counter
    printf("Final counter value: %d\n", shared_counter);
    return 0;
}
```

### Compare and swap

```c
int compare and swap(int *value, int expected, int new value) {
    int temp = *value;
    if (*value == expected)
        *value = new value;
    return temp;
}
```

```c
do {
    while (compare and swap(&lock, 0, 1) != 0)
        ; /* do nothing */
    
    /* critical section */
    lock = 0;
    /* remainder section */
} while (true);
```

### Another algorithm using Test and Set

Although these algorithms satisfy the mutual-exclusion requirement, they do not satisfy the bounded-waiting requirement. We present another algorithm using the ```test and set()``` instruction that satisfies all the critical-section requirements. The common data structures are ```boolean waiting[n];``` ```boolean lock;``` initialized to ```false```.

```c
do {
    waiting[i] = true;
    key = true;
    
    while (waiting[i] && key)
        key = test_and_set(&lock);
    
    waiting[i] = false;
    
    /* critical section */
    
    j = (i + 1) % n;
    while ((j != i) && !waiting[j])
        j = (j + 1) % n;
    
    if (j == i)
        lock = false;
    else
        waiting[j] = false;
    /* remainder section */
} while (true);
```

### And now we have an example of using ```test and set``` algorithm that fulfills bounded-waiting mutual exclusion in an entire C code
```c
#include <stdio.h>
#include <pthread.h>
#include <stdatomic.h>
#include <stdbool.h>
#include <unistd.h>

#define NUM_THREADS 3

// Global variables for the locking mechanism
atomic_bool lock = false;         // Atomic lock variable
bool waiting[NUM_THREADS] = {false};  // Array to track which threads are waiting

// Atomic test-and-set function
bool test_and_set(atomic_bool *target) {
    // Atomically set *target to true and return the old value
    return atomic_exchange(target, true);
}

// Function simulating the critical section
void critical_section(int id) {
    printf("Thread %d: Entering critical section\n", id);
    sleep(1);  // Simulate work in the critical section
    printf("Thread %d: Leaving critical section\n", id);
}

// Function executed by each thread
void *thread_function(void *arg) {
    int i = *(int *)arg;  // Thread's unique identifier

    do {
        // ** Entry Section: Begin trying to acquire the lock **

        waiting[i] = true;  // Mark this thread as waiting
        bool key = true;    // Start with key as true, indicating we want the lock

        // Try to acquire the lock using test_and_set
        while (waiting[i] && key) {
            key = test_and_set(&lock);  // If lock is already true, keep spinning
        }

        waiting[i] = false;  // Thread has acquired the lock, mark as no longer waiting

        // ** Critical Section **
        critical_section(i);

        // ** Exit Section: Release the lock and ensure fair handoff to waiting threads **

        int j = (i + 1) % NUM_THREADS;  // Start checking the next thread in line
        while ((j != i) && !waiting[j]) {
            // Move to the next thread if it's not waiting
            j = (j + 1) % NUM_THREADS;
        }

        if (j == i) {
            // If no other threads are waiting, release the lock
            lock = false;
        } else {
            // If a waiting thread is found, pass the lock to it
            waiting[j] = false;
        }

        // ** Remainder Section: Do other work outside of critical section **
        sleep(1);  // Simulate some non-critical work
    } while (true);  // Continue indefinitely

    return NULL;
}

int main() {
    pthread_t threads[NUM_THREADS];
    int thread_ids[NUM_THREADS];

    // Create and start threads
    for (int i = 0; i < NUM_THREADS; i++) {
        thread_ids[i] = i;  // Assign an ID to each thread
        pthread_create(&threads[i], NULL, thread_function, &thread_ids[i]);
    }

    // Wait for all threads to finish (for demonstration; here, they run indefinitely)
    for (int i = 0; i < NUM_THREADS; i++) {
        pthread_join(threads[i], NULL);
    }

    return 0;
}
```
### Mutex Lock

Operating-systems designers build software tools to solve the critical-section problem. The simplest of these tools is the mutex lock. (In fact, the term mutex is short for mutual exclusion.) We use the mutex lock to protect critical regions and thus prevent race conditions. That is, a process must acquire the lock before entering a critical section; it releases the lock when it exits the critical section. The ```acquire()``` function acquires the lock, and the ```release()``` function releases the lock.

A mutex lock has a boolean variable available whose value indicates if the lock is available or not. If the lock is available, a call to ```acquire()``` succeeds, and the lock is then considered unavailable. A process that attempts to acquire an unavailable lock is blocked until the lock is released.

```c
    //acquire definition
    void acquire() {
        while (!available)
            ; /* busy wait */
        available = false;  
    }

    //release definition
    void release() {
        available = true;
    }  
```
Mutex locks are often implemented using one of the hardware mechanisms, and we leave the description of this technique as an exercise.

#### Solution to the critical-section problem using mutex locks.
```c
    do {
        +-------------------+
        |   acquire lock    |
        +-------------------+

            critical section

        +-------------------+
        |   release lock    |
        +-------------------+

            remainder section

    } while (true);

```
#### Disadvantage:
-> requires ```busy waiting```. Also called a ```spinlock``` because the process “spins” while waiting for the lock to become available.
#### Advantage:
-> no ```context switch``` is required when a process must wait on a lock, and a ```context switch``` may take considerable time.

## Semaphores 

A `semaphore` S is an integer variable that, apart from initialization, is accessed only through two standard atomic operations: `wait()` and `signal()`. The wait() operation was originally; `signal()` was originally called V. The definition of `wait()` is as follows:
```c
void wait(S) {
    while (S <= 0)
        ; // busy wait
    S--;
}
```
The definition of signal() is as follows:
```c
void signal(S) {
    S++;
}
```
This is how a semaphore implementation shoul be
```c
#include <stdio.h>
#include <pthread.h>
#include <semaphore.h>
#include <unistd.h>

// Define a semaphore
sem_t semaphore;

// Function that will be executed by threads
void* worker_function(void* arg) {
    int thread_id = *(int*)arg;

    // Wait operation (P operation) - Decrements the semaphore
    // If the semaphore's value is 0, the thread will block until it's non-zero
    sem_wait(&semaphore); // ATOMIC

    printf("Thread %d: Entering critical section\n", thread_id);

    // Simulate critical section with sleep
    sleep(2);

    printf("Thread %d: Exiting critical section\n", thread_id);

    // Signal operation (V operation) - Increments the semaphore
    // If threads are waiting, one will be awakened
    sem_post(&semaphore); // ATOMIC

    return NULL;
}

int main() {
    // Initialize the semaphore with:
    // - Initial value: 2 (allowing two threads in critical section at a time)
    // - Shared across threads: 0 (not shared across processes)
    sem_init(&semaphore, 0, 2); // ATOMIC

    pthread_t threads[5];
    int thread_ids[5];

    // Create 5 threads
    for (int i = 0; i < 5; i++) {
        thread_ids[i] = i + 1;
        pthread_create(&threads[i], NULL, worker_function, &thread_ids[i]);
    }

    // Wait for all threads to finish
    for (int i = 0; i < 5; i++) {
        pthread_join(threads[i], NULL);
    }

    // Destroy the semaphore
    sem_destroy(&semaphore); // ATOMIC

    return 0;
}

```
### !
We also can have nother type of synchronization in which a thread waits for another to reach a specific point, not only to finish it's critical section.
```c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <semaphore.h>

// Define the semaphore
sem_t sem;

void* thread1_function(void* arg) {
    printf("Thread 1: Starting execution.\n");

    // Simulate work before the critical point
    printf("Thread 1: Doing some work before the critical point...\n");
    sleep(2);

    // Signal the semaphore at the critical point
    printf("Thread 1: Reached the critical point, signaling Thread 2.\n");
    sem_post(&sem);

    // Simulate more work after the critical point
    printf("Thread 1: Doing some work after the critical point...\n");
    sleep(2);

    printf("Thread 1: Finished execution.\n");
    return NULL;
}

void* thread2_function(void* arg) {
    printf("Thread 2: Waiting for Thread 1 to reach the critical point.\n");

    // Wait on the semaphore
    sem_wait(&sem);

    // Proceed after the semaphore is signaled
    printf("Thread 2: Detected that Thread 1 reached the critical point.\n");
    printf("Thread 2: Proceeding with its execution.\n");

    printf("Thread 2: Finished execution.\n");
    return NULL;
}

int main() {
    pthread_t thread1, thread2;

    // Initialize the semaphore with an initial value of 0
    sem_init(&sem, 0, 0);

    // Create the threads
    pthread_create(&thread1, NULL, thread1_function, NULL);
    pthread_create(&thread2, NULL, thread2_function, NULL);

    // Wait for the threads to finish
    pthread_join(thread1, NULL);
    pthread_join(thread2, NULL);

    // Destroy the semaphore
    sem_destroy(&sem);

    printf("Main: Program finished.\n");
    return 0;
}

```
#### Visual explanation of how it works:
```txt
               +-------------------+
               |   Thread 1        |
               +-------------------+
               | Start             |
               | Work Before       |
               | Critical Point    |
               |   (Signal) ------>+----------------+
               | Work After        |                |
               | Finish            |                v
               +-------------------+         +-------------------+
                                             |   Thread 2        |
                                             +-------------------+
                                             | Wait on Semaphore |
                                             | Proceed After     |
                                             | Critical Point    |
                                             | Finish            |
                                             +-------------------+
```

#### Definition of semaphores for a better understanding
```c
#include <stdio.h>
#include <stdlib.h>

// Structure to represent a semaphore
typedef struct {
    int value;     // Semaphore value
    int list;      // Simulating a list of blocked processes (for simplicity, just a counter here)
} semaphore;

// Wait (P) function
void wait(semaphore *S) {
    S->value--; // Decrement the semaphore value
    if (S->value < 0) {
        // Simulate adding the process to the wait list and blocking
        S->list++;
        printf("Process blocked. Processes waiting: %d\n", S->list);
    } else {
        printf("Process can proceed. Semaphore value: %d\n", S->value);
    }
}

// Post (V) function
void post(semaphore *S) {
    S->value++; // Increment the semaphore value
    if (S->value <= 0) {
        // Simulate removing a process from the wait list and unblocking it
        S->list--;
        printf("Unblocking a process. Processes waiting: %d\n", S->list);
    }
    printf("Semaphore value after post: %d\n", S->value);
}

int main() {
    semaphore S;
    S.value = 1; // Initialize the semaphore with 1
    S.list = 0;  // No processes are waiting initially

    printf("Initial semaphore value: %d\n", S.value);

    // First wait call
    printf("\nCalling wait(S)...\n");
    wait(&S);

    // Second wait call
    printf("\nCalling wait(S)...\n");
    wait(&S);

    // First post call
    printf("\nCalling post(S)...\n");
    post(&S);

    // Second post call
    printf("\nCalling post(S)...\n");
    post(&S);

    return 0;
}
```
#### Usage:
There are 2 types of semaphores: 
<br>-> `counting` semaphore (can range over an unrestricted domain);
<br>-> `binary` semaphores (can range only between `0` and `1`).
<br>On systems that do not provide `mutex` locks, `binary` semaphores can be used instead for providing mutual exclusion.

#### Counting semaphores:
-> control acces to a given resource consisting of a finite number of instances;
<br>-> semaphore is initialized with number of instances abalable
<br>-> if a process wants access to an instance performs a `wait()` operation
<br>-> when a process release a resource, it performs a `signal()`/`post()` operation

### Deadlocks and Starvation

The implementation of a semaphore with a waiting queue may result in a situation where two or more processes are waiting indefinitely for an event that can be caused only by one of the waiting processes. The event in question is the execution of a `signal()` operation. When such a state is reached, these processes are said to be `deadlocked`.

```
       P0                        P1
  +-------------------------------------+   
     wait(S);                  wait(Q);
     wait(Q);                  wait(S);
       ...                       ...
       ...                       ...
    signal(S);                signal(Q);
    signal(Q);                signal(S);

```
### Priority Inversion

Assume we have three processes— L, M, and H —whose priorities follow the order L < M < H. Assume that process H requires resource R, which is currently being accessed by process L. Ordinarily, process H would wait for L to finish using resource R. However, now suppose that process M becomes runnable, thereby preempting process L. Indirectly, a process with a lower priority—process M—has affected how long process H must wait for L to relinquish resource R. A `priority-inheritance protocol` would allow process L to temporarily inherit the priority of process H, thereby preventing process M from preempting its execution. When process L had finished using resource R, it would relinquish its inherited priority from H and assume its original priority. Because resource R would now be available, process H —not M—would run next.

So deduced from the example a `priority-inheritance protocol` is when all processes that are accessing resourcesneeded by a higher-priority process inherit the higher priority until they are finished with the resources in question.

## Classic Problems of Synchronization

### 1.The Bounded-Buffer Problem

#### Problem statement:
[Check](0x02.process_synchronization.md) the beginning of this chapter.

#### Shared data:
```c
    int n;                      // pool consists of n buffers
    semaphore mutex = 1;        // mutual exclusion for accesses of the buffer pool
    semaphore empty = n;        // number of full buffers
    semaphore full = 0;         // number of empty buffers
```
#### How to avoid this problem:
```c
                    /*Producer process*/
    do {

    /* produce an item in next produced */
    
    wait(empty);
    wait(mutex);
    
    /* add next produced to the buffer */
    
    signal(mutex);
    signal(full);
    } while (true);
/*-------------------------------------------------------*/
                    
                     /*Consumer process*/
    do {
        wait(full);
        wait(mutex);
        
        /* remove an item from buffer to next consumed */
        
        signal(mutex);
        signal(empty);
        
        /* consume the item in next consumed */
        
    } while (true);
```

### 2.The Readers – Writers Problem

#### Problem statement:
Suppose that a database is to be shared among several concurrent processes. We distinguish between these two types of processes by referring to the former as `readers` and to the latter as `writers`. Obviously, if two `readers` access the shared data simultaneously, no adverse effects will result. However, if a writer and some other process access the database simultaneously, chaos may ensue.

#### Shared data:
```c
    semaphore rw_mutex = 1;     // mutual exclusion for writers
    semaphore mutex = 1;        // mutual exclusion when the read_count is updated
    int read_count = 0;         // how many processes are currently reading
```
#### How to avoid this problem:
```c
        ->Writer process<-

    do {
        wait(rw_mutex);
        . . .
        /* writing is performed */
        . . .
        signal(rw_mutex);
    } while (true);
```
```c
        ->Reader process<-

    do {
        wait(mutex);
        read count++;
        if (read_count == 1)
            wait(rw_mutex);
        signal(mutex);
        . . .
        /* reading is performed */
        . . .
        wait(mutex);
        read_count--;
        if (read_count == 0)
            signal(rw_mutex);
        signal(mutex);
    } while (true);
```

## Monitors

A `monitor type` is an abstract data type that includes a set of programmer-defined operations that are provided with mutual exclusion within the monitor. The monitor type also declares the variables whose values define the state of an instance of that type, along with the bodies of functions that operate on those variables.

```
    MONITOR WITH CONDITION VARIABLES

    !only one process at at time is active within monitor!
                                        +------+   +------+   +------+   +-----+
                            ┌-----------|Thread|-->|Thread|-->|Thread|-->| ... |
    +---------------------------+       +------+   +------+   +------+   +-----+
    |   +-------------------+   |                   [ENTRY QUEUE]
    |   |     SHARED DATA   |   |
    |   |  x->□->□->□       |   |   }   queue associated with
    |   |  y->□->□          |   |   }   x, y conditions
    |   |[data declaration] |   |
    |   +-------------------+   |
    |            |              |
    |    +---------------+      |
    |    |   OPERATIONS   |     |   ->a function defined within monitor can access 
    |    |   [  ...   ]   |     |       only variables declared locally
    |    |   [Method 1]   |     |
    |    |   [Method 2]   |     |
    |    +---------------+      |
    |            |              |
    |   +-------------------+   |
    |   |   INITIALIZATION  |   |
    |   |      CODE         |   |
    |   +-------------------+   |
    +---------------------------+
```
#### X, Y conditions

Named also `condition construct` are needed by a programmer who needs to write a tailor-made synchronization scheme. The only operations that can be invoked on a `X, Y conditions` are:
<br>-> `wait` until a condition becomes true (eg. buffer is not empty)
<br>-> `signal` other processes that a condition became true (eg. buffer is not full anymore) 

```c
monitor Buffer {
    condition X;  // condition asociate to a empty buffer
    condition Y;  // condition asociated to a full buffer
    int count = 0;
    int maxSize = 10;

    void produce(int item) {
        if (count == maxSize) {  // Buffer plin
            wait(Y);             // waits until the buffer is empty
        }
        addItemToBuffer(item);
        count++;
        signal(X);  // notify the consummers that the buffer is empty
    }

    int consume() {
        if (count == 0) {  // empty
            wait(X);       // waits until the buffer is not empty anymore
        }
        int item = removeItemFromBuffer();
        count--;
        signal(Y);  // notify the consummers that the buffer is not empty anymore
        return item;
    }
}

```

#### And this is a complete implementation in c++ of a monitor for as better understanding
```cpp
#include <iostream>
#include <queue>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <vector>

using namespace std;

class Monitor {
private:
    queue<int> buffer;                 // Shared buffer
    const size_t maxSize;              // Maximum size of the buffer
    mutex mtx;                         // Mutex for mutual exclusion
    condition_variable notEmpty;       // Condition: buffer is not empty (X)
    condition_variable notFull;        // Condition: buffer is not full (Y)

public:
    // Constructor to initialize the monitor
    Monitor(size_t size) : maxSize(size) {}

    // Producer method: add an item to the buffer
    void produce(int item) {
        unique_lock<mutex> lock(mtx); // Lock the mutex for exclusive access

        // Wait until there is space in the buffer (wait on condition Y)
        notFull.wait(lock, [this]() { return buffer.size() < maxSize; });

        // Add the item to the buffer
        buffer.push(item);
        cout << "Produced: " << item << endl;

        // Notify one consumer that the buffer is no longer empty
        notEmpty.notify_one();
    }

    // Consumer method: remove an item from the buffer
    int consume() {
        unique_lock<mutex> lock(mtx); // Lock the mutex for exclusive access

        // Wait until the buffer is not empty (wait on condition X)
        notEmpty.wait(lock, [this]() { return !buffer.empty(); });

        // Remove the item from the buffer
        int item = buffer.front();
        buffer.pop();
        cout << "Consumed: " << item << endl;

        // Notify one producer that the buffer is no longer full
        notFull.notify_one();

        return item;
    }
};

// Producer function to run in a thread
void producer(Monitor& monitor, int itemsToProduce) {
    for (int i = 1; i <= itemsToProduce; ++i) {
        monitor.produce(i); // Produce items
    }
}

// Consumer function to run in a thread
void consumer(Monitor& monitor, int itemsToConsume) {
    for (int i = 0; i < itemsToConsume; ++i) {
        monitor.consume(); // Consume items
    }
}

// Main function
int main() {
    const size_t bufferSize = 5;    // Size of the buffer
    const int itemsToProduce = 10; // Number of items to produce/consume

    Monitor monitor(bufferSize); // Create the monitor object

    // Create producer and consumer threads
    thread producerThread(producer, ref(monitor), itemsToProduce);
    thread consumerThread(consumer, ref(monitor), itemsToProduce);

    // Wait for threads to finish
    producerThread.join();
    consumerThread.join();

    return 0;
}

```
###  To be continued : Dining Philosophers and Deadlocks